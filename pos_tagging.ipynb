{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pos-tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pGK0m9Sia8Wm",
        "TfugAaI1S9kQ"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNleGA6s0stl9mPqJtfMvXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6906a75a3b994bc2853b4f53ab3d565e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed9a7cae81fc440abb06c1db03d6e00e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b22d638a2a304ec1b0cb2fc59fb69421",
              "IPY_MODEL_f754e134506041b78789f9b474fc6333"
            ]
          }
        },
        "ed9a7cae81fc440abb06c1db03d6e00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b22d638a2a304ec1b0cb2fc59fb69421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72ebe3b121c24663bb0d120683d3c712",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 164437832,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 164437832,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efdeef77b45146bbad87e9221b0f0c71"
          }
        },
        "f754e134506041b78789f9b474fc6333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6023fb06760d49afbaabb43da77e3403",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 164M/164M [02:14&lt;00:00, 1.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0183a7442ad460aad8494948eb9bf36"
          }
        },
        "72ebe3b121c24663bb0d120683d3c712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efdeef77b45146bbad87e9221b0f0c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6023fb06760d49afbaabb43da77e3403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0183a7442ad460aad8494948eb9bf36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vydra-v-getrax/Chinese_pos_tagging/blob/main/pos_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frOQnXhmK0u0"
      },
      "source": [
        "# Comparison of POS tagging models for Chinese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94LTljpmW5HE"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PRR0DG4Jg4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd49157d-597b-439f-84b5-146646e72611"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfugAaI1S9kQ"
      },
      "source": [
        "### Getting data for gold standard\n",
        "\n",
        "You don't need that, the dataset has already been annotated.\n",
        "\n",
        "Go to see: https://docs.google.com/spreadsheets/d/1ZG3xwqC7z857qjFdm3Z02yz968ArbGv7MJ-EDdw3yew/edit?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPKm2WVwbxve"
      },
      "source": [
        "!pip install fastHan\n",
        "from fastHan import fastHan\n",
        "model=FastHan()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od_gVGZDnAPK"
      },
      "source": [
        "def load_gold(path, model):\n",
        "\n",
        "    \"\"\"\n",
        "    This function takes texts from .txt files and annotates them with fastHan\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        file = f.readlines()\n",
        "    pairs = [sent.split(' ||| ') for sent in file]\n",
        "    dct = []\n",
        "    # ru = []\n",
        "    for id_sent, pair in tqdm(enumerate(pairs)):\n",
        "        ru = pair[0]\n",
        "        zh = ''.join(pair[1].split())\n",
        "        answer = model(zh, target='POS')[0]\n",
        "        count = 0\n",
        "        for k, token in enumerate(answer):\n",
        "            id_token = [count+i for i in range(len(token[0]))]\n",
        "            count+= len(token[0])\n",
        "            dct.append([id_sent, token[0], token[1], id_token, zh, ru])\n",
        "\n",
        "    res = pd.DataFrame(columns=['id_sent', 'token', 'pos', 'id_token', 'zho', 'rus'], data=dct)\n",
        "    return res"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EvOv5FOTv0S"
      },
      "source": [
        "gold4 = load_gold('pos/alignment/gold4_900.txt')\n",
        "gold2 = load_gold('pos/alignment/gold2_125.txt')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "H9Qt0OPEZUhW",
        "outputId": "fc93efe8-47ee-4ba7-c5db-7b23f9b226bf"
      },
      "source": [
        "gold4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_sent</th>\n",
              "      <th>token</th>\n",
              "      <th>pos</th>\n",
              "      <th>id_token</th>\n",
              "      <th>zho</th>\n",
              "      <th>rus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>它</td>\n",
              "      <td>PN</td>\n",
              "      <td>[0]</td>\n",
              "      <td>它没有翅翼。</td>\n",
              "      <td>крыльев у него нет .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>没有</td>\n",
              "      <td>VE</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>它没有翅翼。</td>\n",
              "      <td>крыльев у него нет .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>翅翼</td>\n",
              "      <td>NN</td>\n",
              "      <td>[3, 4]</td>\n",
              "      <td>它没有翅翼。</td>\n",
              "      <td>крыльев у него нет .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>。</td>\n",
              "      <td>PU</td>\n",
              "      <td>[5]</td>\n",
              "      <td>它没有翅翼。</td>\n",
              "      <td>крыльев у него нет .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>“</td>\n",
              "      <td>PU</td>\n",
              "      <td>[0]</td>\n",
              "      <td>“是优雅，生机勃勃和32号鞋的鞋后跟——瞧，这是个淫荡的女人吗？</td>\n",
              "      <td>— изящество , трепет , каблучки тридцать второ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11795</th>\n",
              "      <td>544</td>\n",
              "      <td>人民</td>\n",
              "      <td>NN</td>\n",
              "      <td>[34, 35]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11796</th>\n",
              "      <td>544</td>\n",
              "      <td>大会堂</td>\n",
              "      <td>NN</td>\n",
              "      <td>[36, 37, 38]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11797</th>\n",
              "      <td>544</td>\n",
              "      <td>了</td>\n",
              "      <td>SP</td>\n",
              "      <td>[39]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11798</th>\n",
              "      <td>544</td>\n",
              "      <td>。</td>\n",
              "      <td>PU</td>\n",
              "      <td>[40]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11799</th>\n",
              "      <td>544</td>\n",
              "      <td>”</td>\n",
              "      <td>PU</td>\n",
              "      <td>[41]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11800 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id_sent  ...                                                rus\n",
              "0            0  ...                               крыльев у него нет .\n",
              "1            0  ...                               крыльев у него нет .\n",
              "2            0  ...                               крыльев у него нет .\n",
              "3            0  ...                               крыльев у него нет .\n",
              "4            1  ...  — изящество , трепет , каблучки тридцать второ...\n",
              "...        ...  ...                                                ...\n",
              "11795      544  ...  слышите , как рыдает ? она поняла , что теперь...\n",
              "11796      544  ...  слышите , как рыдает ? она поняла , что теперь...\n",
              "11797      544  ...  слышите , как рыдает ? она поняла , что теперь...\n",
              "11798      544  ...  слышите , как рыдает ? она поняла , что теперь...\n",
              "11799      544  ...  слышите , как рыдает ? она поняла , что теперь...\n",
              "\n",
              "[11800 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXV5aKvSZzhS"
      },
      "source": [
        "gold4.to_csv('/pos/alignment/gold4_900.csv')\n",
        "gold2.to_csv('/pos/alignment/gold4_125.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObQig4ZMt0c7"
      },
      "source": [
        "## Getting russian parallel data\n",
        "\n",
        "1.   Get sentences from .txt aligned format\n",
        "2.   Preprocess with pymorphy2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1ae4NPXt3kf"
      },
      "source": [
        "def load_ru(path): \n",
        "\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        file = f.readlines()\n",
        "    ru = [sent.split(' ||| ')[0] for sent in file]\n",
        "    dct = []\n",
        "    ru_words = [sent.split() for sent in ru]\n",
        "    return ru_words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-zgWUaCun5f"
      },
      "source": [
        "ru_gold2 = load_ru('/pos/alignment/gold2_125.txt')\n",
        "ru_gold4 = load_ru('/pos/alignment/gold4_900.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRwGPuykz1Of",
        "outputId": "b5d645be-58a7-4bd7-bbe7-39239b05f508"
      },
      "source": [
        "!pip install pymorphy2\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 8.2MB/s \n",
            "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q1hXVkuzIn8"
      },
      "source": [
        "import string\n",
        "PUNCT = string.punctuation+'...'+'—'+'–'+'«'+'»'+'№'+'--'+'…'   #add PUNCT to Pymorphy2 tags\n",
        "import re\n",
        "\n",
        "def tag_rus(data, nick):\n",
        "\n",
        "    '''\n",
        "    Annotate russian sentences\n",
        "\n",
        "    data: list of lists \n",
        "    nick: string for nickname of set (for alignment)\n",
        "    '''\n",
        "\n",
        "    dct = {'word': [], 'pos': [], 'id_sent': [], 'id_token': []}\n",
        "    for id_sent, sentence in enumerate(data):\n",
        "        pos_tags = []\n",
        "        for id_token, word in enumerate(sentence):\n",
        "            p = morph.parse(word.replace('ё', 'ё').replace('ё', 'ё').replace('й', 'й'))[0].tag.POS\n",
        "            if word in PUNCT:\n",
        "                p = 'PUNCT'\n",
        "            if re.search('\\d', word):\n",
        "                p = 'NUMR'\n",
        "            dct['word'].append(word)\n",
        "            dct['pos'].append(p)\n",
        "            dct['id_sent'].append(id_sent)\n",
        "            dct['id_token'].append(id_token)\n",
        "\n",
        "    pos = pd.DataFrame(columns=['word', 'pos', 'id_sent', 'id_token'], data=dct)\n",
        "    pos['nickname'] = [nick for i in range(pos.shape[0])]\n",
        "\n",
        "    return pos\n",
        "\n",
        "ru2 = tag_rus(ru_gold2, 'gold2')\n",
        "ru4 = tag_rus(ru_gold4, 'gold4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CapIlQQd-XRs"
      },
      "source": [
        "ru = pd.concat([ru2, ru4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbiMbHEEJHcA"
      },
      "source": [
        "## Get gold standard\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ncIuZ0QJu5o"
      },
      "source": [
        "# This enables access to google spreadsheets\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joJ9vCFnJzVk"
      },
      "source": [
        "my_book = gc.open_by_key('1ZG3xwqC7z857qjFdm3Z02yz968ArbGv7MJ-EDdw3yew') # link to our data"
      ],
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk7QL_JaKF4n"
      },
      "source": [
        "worksheet_list = my_book.worksheets()\n",
        "col_names = [\"num\", 'id_sent', 'token', 'pos', 'true_pos', 'id_token', 'zho', 'rus']\n",
        "stand = pd.DataFrame(columns=col_names)\n",
        "list_of_counts = []\n",
        "list_of_df = []\n",
        "for i in ['gold2_125', 'gold4_365', 'gold4_continue']: # for 'manual' spreadsheet\n",
        "    my_sheet = my_book.worksheet(i)\n",
        "    list_of_lists = my_sheet.get_all_values()\n",
        "    df = pd.DataFrame(data=list_of_lists)\n",
        "    df.columns = col_names # 0th row to col names\n",
        "    df['nickname'] = [i for _ in list_of_lists]\n",
        "    df.drop(df.index[0], inplace=True) # drop 0th row\n",
        "    list_of_df.append(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4VFPm_qQtsT"
      },
      "source": [
        "# This loads all annotated sheets to one pandas df\n",
        "\n",
        "full = pd.concat([list_of_df[0], list_of_df[1], list_of_df[2]], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpRHRe8NKF1L"
      },
      "source": [
        "list_of_df[2].id_sent = list_of_df[2].id_sent.apply(lambda x: int(x)+365)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "vYNDmQEEERTo",
        "outputId": "94df34c2-260f-45fc-e7de-416455adf15f"
      },
      "source": [
        "full.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>id_sent</th>\n",
              "      <th>token</th>\n",
              "      <th>pos</th>\n",
              "      <th>true_pos</th>\n",
              "      <th>id_token</th>\n",
              "      <th>zho</th>\n",
              "      <th>rus</th>\n",
              "      <th>nickname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21815</th>\n",
              "      <td>11795</td>\n",
              "      <td>909</td>\n",
              "      <td>人民</td>\n",
              "      <td>NN</td>\n",
              "      <td>NN</td>\n",
              "      <td>[34, 35]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "      <td>gold4_continue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21816</th>\n",
              "      <td>11796</td>\n",
              "      <td>909</td>\n",
              "      <td>大会堂</td>\n",
              "      <td>NN</td>\n",
              "      <td>NN</td>\n",
              "      <td>[36, 37, 38]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "      <td>gold4_continue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21817</th>\n",
              "      <td>11797</td>\n",
              "      <td>909</td>\n",
              "      <td>了</td>\n",
              "      <td>SP</td>\n",
              "      <td>SP</td>\n",
              "      <td>[39]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "      <td>gold4_continue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21818</th>\n",
              "      <td>11798</td>\n",
              "      <td>909</td>\n",
              "      <td>。</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>[40]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "      <td>gold4_continue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21819</th>\n",
              "      <td>11799</td>\n",
              "      <td>909</td>\n",
              "      <td>”</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>[41]</td>\n",
              "      <td>你听，正哭呢。”又说：“她知道这消息之后，也就无状可告了，再也不会闯人民大会堂了。”</td>\n",
              "      <td>слышите , как рыдает ? она поняла , что теперь...</td>\n",
              "      <td>gold4_continue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         num  ...        nickname\n",
              "21815  11795  ...  gold4_continue\n",
              "21816  11796  ...  gold4_continue\n",
              "21817  11797  ...  gold4_continue\n",
              "21818  11798  ...  gold4_continue\n",
              "21819  11799  ...  gold4_continue\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkENQZM_J0Dp"
      },
      "source": [
        "### Statistics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L76vY0EEJydR"
      },
      "source": [
        "# I want to write some data to sheets.\n",
        "\n",
        "stat = gc.open_by_key('1OS6sKIF-yJQVwXu2RVZH_P7EI4_wreAyXxh9ybf8Kmg') #usable link to stat file\n",
        "\n",
        "def write_to_stats(my_book, name, data):\n",
        "    \"\"\"\n",
        "    Writes dataframe to sheets.\n",
        "    my_book : sheet,\n",
        "    name : name of list\n",
        "    data: your df\n",
        "    \"\"\"\n",
        "    worksheet = my_book.add_worksheet(title=name, rows=\"100\", cols=\"100\")\n",
        "    set_with_dataframe(worksheet, data)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf7djlqTLfsT"
      },
      "source": [
        "write_to_stats(stat, full.columns, 'dataset', full)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zye2a71qMi6p",
        "outputId": "4021930f-60b2-46f1-9671-27c64c01c2c2"
      },
      "source": [
        "# Get statistics \n",
        "write_to_stats(stat, ['true_pos', 'number'], 'value_counts', pd.DataFrame(full.true_pos.value_counts()).reset_index())\n",
        "\n",
        "cols = ['accuracy', 'precision', 'recall', 'f1']\n",
        "write_to_stats(stat, 'manual_results', pd.DataFrame([accuracy_score(full.true_pos, full.pos), \n",
        "                            precision_score(full.true_pos, full.pos, average='macro'),\n",
        "                            recall_score(full.true_pos, full.pos, average='macro'), \n",
        "                            f1_score(full.true_pos, full.pos, average='macro')], index=[cols]).reset_index())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMY9-RE4RgV2",
        "outputId": "f7bffa03-d538-448e-9085-fd7ef25468c8"
      },
      "source": [
        "# Group by sentences\n",
        "sentences = full.groupby(['nickname', 'id_sent']).agg({'token':lambda x: list(x),\n",
        "                                                      'pos': lambda x: list(x), \n",
        "                                                      'id_token': lambda x: list(x)})\n",
        "N_char = sum(full.token.apply(lambda x: len(x)))\n",
        "N_sent = sentences.count()[0]\n",
        "N_words = full.shape[0]\n",
        "\n",
        "print(f'Общее число предложений: {N_sent}\\n\\\n",
        "Общее число слов: {N_words}\\n\\\n",
        "Общее число символов: {N_char}\\n\\\n",
        "\\nСредняя длина предложения в словах: {np.mean(sentences.token.apply(lambda x: len(x)))}\\n\\\n",
        "Средняя длина предложения в символах: {np.mean(sentences.token.apply(lambda x: len(\"\".join(x))))}\\n\\\n",
        "Средня длина слова: {np.mean(full.token.apply(lambda x: len(x)))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Общее число предложений: 1036\n",
            "Общее число слов: 21820\n",
            "Общее число символов: 31921\n",
            "\n",
            "Средняя длина предложения в словах: 21.06177606177606\n",
            "Средняя длина предложения в символах: 30.81177606177606\n",
            "Средня длина слова: 1.4629239230064162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh3jd_UMQo_5"
      },
      "source": [
        "# Main part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59csOiaLsndW"
      },
      "source": [
        "## Load reference table for postags of different tools\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4wt-qeBsndd"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "ref_table = gc.open_by_key('1w7qRF3H2GmFOW5HvMIGrgIBC8RfK17UmkMJpzcOwAaQ')\n",
        "ref_table = ref_table.get_worksheet(0)\n",
        "list_table = ref_table.get_all_values()\n",
        "ref_table = pd.DataFrame(data=list_table)\n",
        "ref_table.columns = ref_table.iloc[0]\n",
        "ref_table.drop(ref_table.index[0], inplace=True)\n",
        "ref_table['fastHan'] = ref_table.fastHan.apply(lambda x: x.strip())\n",
        "\n",
        "for col in ref_table.iloc[:, 2:]:\n",
        "    ref_table[col] = ref_table[col].apply(lambda x: x.split(', '))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVyqxXTq07r4"
      },
      "source": [
        "### Comparison by words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYtOgFnfQrFW"
      },
      "source": [
        "pos_tools = ['ckiptagger', 'pkuseg' ,'fastHan', 'PyNLPIR', 'stanza', 'spacy', 'ltp', 'jiagu', 'lac', 'snownlp']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlfVT_AzshPb"
      },
      "source": [
        "# How many different tags refer to target set\n",
        "\n",
        "count_tags = pd.DataFrame(columns=[t for t in pos_tools if t != 'fastHan'], index=ref_table['fastHan'])\n",
        "for tool in pos_tools:\n",
        "    if tool != 'fastHan':\n",
        "        count_tags[tool] = ref_table[tool].apply(lambda x: len(x)).tolist()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uwte4mB4EVp"
      },
      "source": [
        "write_to_stats(stat, 'count_tags', count_tags)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNuDRaxn2ohr"
      },
      "source": [
        "### Install models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsWp1N6XQrB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b99c2ae-28f6-4cda-8b65-6b4c18e2ee1b"
      },
      "source": [
        "for tool in pos_tools:\n",
        "    try:\n",
        "        if tool == 'spacy':\n",
        "            !pip install -U spacy\n",
        "            !python -m spacy download zh_core_web_sm\n",
        "        else:\n",
        "          !pip install {tool}\n",
        "    except:\n",
        "        print(\"Failed in installing\", tool)\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ckiptagger\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/bc/5cbf8d019167d5e5e1775069fb8b71a08691ab847e2926bbe7dee9a19010/ckiptagger-0.2.1-py3-none-any.whl\n",
            "Installing collected packages: ckiptagger\n",
            "Successfully installed ckiptagger-0.2.1\n",
            "Collecting pkuseg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/59/09644bdf620738f93520c28d83a67b9550e446705eac6438f444bb6563ca/pkuseg-0.0.25-cp37-cp37m-manylinux1_x86_64.whl (50.2MB)\n",
            "\u001b[K     |████████████████████████████████| 50.2MB 83kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pkuseg) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from pkuseg) (0.29.23)\n",
            "Installing collected packages: pkuseg\n",
            "Successfully installed pkuseg-0.0.25\n",
            "Collecting fastHan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/cf/f604d4c95348d2ec954fba13ab3317444d5117f4c4c386a049ae2305a29c/fastHan-1.7-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25hCollecting FastNLP>=0.5.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/76/c80dc6ba0c29ca0ac7ae8b15d5e443628ed901651b55d4edba9436de59ae/FastNLP-0.6.0.tar.gz (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastHan) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from FastNLP>=0.5.5->fastHan) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.7/dist-packages (from FastNLP>=0.5.5->fastHan) (4.41.1)\n",
            "Requirement already satisfied: prettytable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from FastNLP>=0.5.5->fastHan) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from FastNLP>=0.5.5->fastHan) (2.23.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from FastNLP>=0.5.5->fastHan) (2.2.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from FastNLP>=0.5.5->fastHan) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastHan) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->FastNLP>=0.5.5->fastHan) (4.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->FastNLP>=0.5.5->fastHan) (0.2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->FastNLP>=0.5.5->fastHan) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->FastNLP>=0.5.5->fastHan) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->FastNLP>=0.5.5->fastHan) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->FastNLP>=0.5.5->fastHan) (1.24.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->FastNLP>=0.5.5->fastHan) (56.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->prettytable>=0.7.2->FastNLP>=0.5.5->fastHan) (3.4.1)\n",
            "Building wheels for collected packages: FastNLP\n",
            "  Building wheel for FastNLP (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FastNLP: filename=FastNLP-0.6.0-cp37-none-any.whl size=357808 sha256=7fe79180d274560afddfd8d09b95b6f420a6f7cf77156e19234f9f79ba9e6c0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/d8/e0/3bb2ec341c37364582474ade181e480a2fc1b490fef5fb6b34\n",
            "Successfully built FastNLP\n",
            "Installing collected packages: FastNLP, fastHan\n",
            "Successfully installed FastNLP-0.6.0 fastHan-1.7\n",
            "Collecting PyNLPIR\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/66/79d353119143f92fdf80aea0e8b5b8289baf60708a3202fc7a4d3a530d0e/PyNLPIR-0.6.0-py2.py3-none-any.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from PyNLPIR) (8.0.0)\n",
            "Installing collected packages: PyNLPIR\n",
            "Successfully installed PyNLPIR-0.6.0\n",
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (56.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2\n",
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 208kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 41.0MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.0)\n",
            "Collecting click<7.2.0,>=7.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.1MB/s \n",
            "\u001b[?25hCollecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 47.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=f7443a76bd1c6204977d59d2a4cd4c70173dafa0d0885d4050d805a4ce7d59b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: catalogue, srsly, pydantic, thinc, spacy-legacy, click, typer, smart-open, pathy, spacy\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: click 8.0.0\n",
            "    Uninstalling click-8.0.0:\n",
            "      Successfully uninstalled click-8.0.0\n",
            "  Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 click-7.1.2 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n",
            "2021-05-22 13:57:53.374937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting zh-core-web-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/zh_core_web_sm-3.0.0/zh_core_web_sm-3.0.0-py3-none-any.whl (49.5MB)\n",
            "\u001b[K     |████████████████████████████████| 49.6MB 155kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from zh-core-web-sm==3.0.0) (3.0.6)\n",
            "Collecting spacy-pkuseg<0.1.0,>=0.0.27\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/c1/c8c5e08eb4c3108c3a0a412955356fdecbb8ceddc49611a54d444c91b014/spacy_pkuseg-0.0.28-cp37-cp37m-manylinux2014_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (56.1.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.7/dist-packages (from spacy-pkuseg<0.1.0,>=0.0.27->zh-core-web-sm==3.0.0) (0.29.23)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.0.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->zh-core-web-sm==3.0.0) (3.0.0)\n",
            "Installing collected packages: spacy-pkuseg, zh-core-web-sm\n",
            "Successfully installed spacy-pkuseg-0.0.28 zh-core-web-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('zh_core_web_sm')\n",
            "Collecting ltp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/f2/1b04210c4bdf8d76dd9cbdd2971313f58997302f7be2f61ccc78dad46feb/ltp-4.1.4.post1-py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.5MB/s \n",
            "\u001b[?25hCollecting pygtrie<2.5,>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/8b/90d0f21a27a354e808a73eb0ffb94db990ab11ad1d8b3db3e5196c882cad/pygtrie-2.4.2.tar.gz\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from ltp) (1.8.1+cu101)\n",
            "Collecting transformers<5.0,>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from ltp) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->ltp) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->ltp) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0,>=4.0.0->ltp) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0,>=4.0.0->ltp) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0,>=4.0.0->ltp) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0,>=4.0.0->ltp) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0,>=4.0.0->ltp) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->ltp) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0,>=4.0.0->ltp) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0,>=4.0.0->ltp) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0,>=4.0.0->ltp) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0,>=4.0.0->ltp) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0,>=4.0.0->ltp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0,>=4.0.0->ltp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0,>=4.0.0->ltp) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0,>=4.0.0->ltp) (3.0.4)\n",
            "Building wheels for collected packages: pygtrie\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.4.2-cp37-none-any.whl size=19063 sha256=d997871ccabd0c202540b902b747bc2e70ce15844be44510ae1bf3f5e35955d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/57/91/73782136379fe419036c5ec0e4070d8b3a35f2a36bd6a94ed8\n",
            "Successfully built pygtrie\n",
            "Installing collected packages: pygtrie, tokenizers, sacremoses, huggingface-hub, transformers, ltp\n",
            "Successfully installed huggingface-hub-0.0.8 ltp-4.1.4.post1 pygtrie-2.4.2 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n",
            "Collecting jiagu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/86/e9473a45fdfdfef23c0ba049ddcb94a062f3e86ec5f2b8732e567afa30f9/jiagu-0.2.3.tar.gz (53.8MB)\n",
            "\u001b[K     |████████████████████████████████| 53.8MB 76kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: jiagu\n",
            "  Building wheel for jiagu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jiagu: filename=jiagu-0.2.3-cp37-none-any.whl size=53824965 sha256=a3d1e6195e8e6c10eb3fb0ce9c67015b3ca32326f1150c27a49bd5fb0d182c7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/de/f6/ae679c815e570e1dbfd2c32c3c842e92549d7ae502f5481868\n",
            "Successfully built jiagu\n",
            "Installing collected packages: jiagu\n",
            "Successfully installed jiagu-0.2.3\n",
            "Collecting lac\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/55bb532621c1e56b860794c9c86851a4ac744610c646a1ca9499e42f5773/LAC-2.1.1.tar.gz (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 79kB/s \n",
            "\u001b[?25hCollecting paddlepaddle>=1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/12/273ec0cdf3164e610aa197425cfcaffcd4b32aa2b7a29ba628b5f29e95c9/paddlepaddle-2.1.0-cp37-cp37m-manylinux1_x86_64.whl (108.8MB)\n",
            "\u001b[K     |████████████████████████████████| 108.8MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (3.12.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (2.23.0)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (4.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (0.3.3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle>=1.6->lac) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->paddlepaddle>=1.6->lac) (56.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle>=1.6->lac) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle>=1.6->lac) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle>=1.6->lac) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle>=1.6->lac) (2.10)\n",
            "Building wheels for collected packages: lac\n",
            "  Building wheel for lac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lac: filename=LAC-2.1.1-py2.py3-none-any.whl size=64820335 sha256=a519665d1fbf31436d6ebbafd6a253a6410054766576b9fd2a28b161de6bfb9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/9b/9111bbb8b9449451732d6e459df4a6b78e98cab166b86990a8\n",
            "Successfully built lac\n",
            "Installing collected packages: paddlepaddle, lac\n",
            "Successfully installed lac-2.1.1 paddlepaddle-2.1.0\n",
            "Collecting snownlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/b3/37567686662100d3bce62d3b0f2adec18ab4b9ff2b61abd7a61c39343c1d/snownlp-0.12.3.tar.gz (37.6MB)\n",
            "\u001b[K     |████████████████████████████████| 37.6MB 89kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: snownlp\n",
            "  Building wheel for snownlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for snownlp: filename=snownlp-0.12.3-cp37-none-any.whl size=37760959 sha256=ae6f6a4ae8b8f8fe574fcecf26643d5b97ffeb0eb33fc7baa8eda77231a4bc41\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/81/25/7c197493bd7daf177016f1a951c5c3a53b1c7e9339fd11ec8f\n",
            "Successfully built snownlp\n",
            "Installing collected packages: snownlp\n",
            "Successfully installed snownlp-0.12.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AuZgzobhCng",
        "outputId": "ada2c4af-bed4-4788-e9fe-4f81ea8f9b96"
      },
      "source": [
        "from ckiptagger import data_utils, WS, POS\n",
        "import pkuseg\n",
        "!pynlpir update\n",
        "import pynlpir\n",
        "import stanza\n",
        "print('import')\n",
        "stanza.download('zh', processors='tokenize, pos')\n",
        "import zh_core_web_sm\n",
        "from ltp import LTP\n",
        "import jiagu\n",
        "from LAC import LAC\n",
        "import snownlp\n",
        "from snownlp import SnowNLP\n",
        "from fastHan import FastHan\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "License updated.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 29.7MB/s]                    \n",
            "2021-05-22 13:59:58 INFO: \"zh\" is an alias for \"zh-hans\"\n",
            "2021-05-22 13:59:58 INFO: Downloading these customized packages for language: zh-hans (Simplified_Chinese)...\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | gsdsimp |\n",
            "| pos       | gsdsimp |\n",
            "| pretrain  | gsdsimp |\n",
            "=======================\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "import\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/zh-hans/tokenize/gsdsimp.pt: 100%|██████████| 1.13M/1.13M [00:00<00:00, 3.16MB/s]\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/zh-hans/pos/gsdsimp.pt: 100%|██████████| 21.3M/21.3M [00:00<00:00, 23.3MB/s]\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/zh-hans/pretrain/gsdsimp.pt: 100%|██████████| 306M/306M [00:56<00:00, 5.46MB/s]\n",
            "2021-05-22 14:01:00 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/decorators.py:70: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
            "  formatvalue=lambda value: \"\")[1:-1]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAjaoUs9QX_C"
      },
      "source": [
        "## Comparison by words _\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz7VTDK5t9Xa"
      },
      "source": [
        "words_tests = {} # for tagged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgHmcbn_bVhp"
      },
      "source": [
        "def run_tools(tool, tests): # by words segmented previously by fasthan\n",
        "    if tool == 'ckiptagger':\n",
        "        # for CKIPtagger you need its dictionaries. Download them and import in any way\n",
        "        ws = WS('/content/drive/MyDrive/data/ckiptagger') \n",
        "        pos = POS(\"/content/drive/My Drive/data/ckiptagger\")\n",
        "        words = ws(full.token)\n",
        "        pos_tags = pos(words)\n",
        "        tests[tool] = pos_tags\n",
        "\n",
        "    if tool == 'pkuseg':\n",
        "        seg = pkuseg.pkuseg(postag=True)\n",
        "        pku_tags = []\n",
        "        for word in tqdm(full.token):\n",
        "            try:\n",
        "                text = seg.cut(word)\n",
        "                pku_tags.append([i[1] for i in text])\n",
        "            except IndexError:\n",
        "                pku_tags.append('')\n",
        "        tests[tool] = pku_tags\n",
        "\n",
        "    if tool == 'PyNLPIR':\n",
        "\n",
        "        pynlpir.open()\n",
        "        word_pos = []\n",
        "        for word in full.token:\n",
        "            try:\n",
        "                word_pos.append([i[1] for i in pynlpir.segment(word, pos_names='raw')])\n",
        "            except:\n",
        "                word_pos.append('')\n",
        "        tests[tool] = word_pos\n",
        "        pynlpir.close()\n",
        "\n",
        "    if tool == 'stanza':\n",
        "\n",
        "        nlp = stanza.Pipeline('zh', processors='tokenize, pos')\n",
        "        word_pos = []\n",
        "        for word in full.token:\n",
        "            doc = nlp(word)\n",
        "            word_pos.append([word.upos for sent in doc.sentences for word in sent.words])\n",
        "        tests[tool] = word_pos\n",
        "\n",
        "    if tool == 'spacy':\n",
        "        nlp = zh_core_web_sm.load()\n",
        "        word_pos = []\n",
        "\n",
        "        for word in full.token:\n",
        "            doc = nlp(word)\n",
        "            word_pos.append([word.pos_ for word in doc])\n",
        "        tests[tool] = word_pos\n",
        "\n",
        "    if tool == 'ltp':\n",
        "        ltp = LTP()\n",
        "        seg, hidden = ltp.seg(full.token.tolist())\n",
        "        pos = ltp.pos(hidden)\n",
        "        word_pos = []\n",
        "        for i in range(len(seg)):\n",
        "            word_pos.append([word for word in pos[i]])\n",
        "        tests[tool] = word_pos\n",
        "\n",
        "    if tool == 'jiagu':\n",
        "        word_pos = []\n",
        "        for word in full.token:\n",
        "            try:\n",
        "                word_pos.append(jiagu.pos([word]))\n",
        "            except:\n",
        "                word_pos.append('')\n",
        "        tests[tool] = word_pos\n",
        "\n",
        "    if tool == 'lac':\n",
        "        lac = LAC(mode='rank')\n",
        "        word_pos = []\n",
        "        for word in full.token:\n",
        "            try:\n",
        "                word_pos.append(lac.run(word)[1])\n",
        "            except:\n",
        "                word_pos.append([''])\n",
        "        tests[tool] = word_pos\n",
        "\n",
        "    if tool == 'snownlp':\n",
        "\n",
        "        word_pos = []\n",
        "\n",
        "        for word in full.token:\n",
        "            try:\n",
        "                word_pos.append([i[1] for i in SnowNLP(word).tags])\n",
        "            except:\n",
        "                word_pos.append('')\n",
        "        tests[tool] = word_pos\n",
        "\n",
        "    if tool == 'fastHan':\n",
        "        model=FastHan()\n",
        "        word_pos = []\n",
        "        for word in full.token:\n",
        "            word_pos.append([tag[3] for tag in model(word, target=\"Parsing\")[0]])\n",
        "        tests[tool] = word_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdVPp6GOF7zd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919,
          "referenced_widgets": [
            "6906a75a3b994bc2853b4f53ab3d565e",
            "ed9a7cae81fc440abb06c1db03d6e00e",
            "b22d638a2a304ec1b0cb2fc59fb69421",
            "f754e134506041b78789f9b474fc6333",
            "72ebe3b121c24663bb0d120683d3c712",
            "efdeef77b45146bbad87e9221b0f0c71",
            "6023fb06760d49afbaabb43da77e3403",
            "a0183a7442ad460aad8494948eb9bf36"
          ]
        },
        "outputId": "308b3b94-9518-4191-c51d-7cd310655989"
      },
      "source": [
        "# This wil take around 20 minutes\n",
        "\n",
        "for tool in pos_tools:\n",
        "    print(f'Processing {tool} ...\\n')\n",
        "    run_tools(tool, words_tests)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ckiptagger ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing pkuseg ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lancopku/pkuseg-python/releases/download/v0.0.16/postag.zip\" to /root/.pkuseg/postag.zip\n",
            "100%|██████████| 41424981/41424981 [00:00<00:00, 70661572.57it/s]\n",
            "100%|██████████| 21820/21820 [00:03<00:00, 7160.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing fastHan ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0.00/144M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "http://212.129.155.247/fasthan/fasthan_base.zip not found in cache, downloading to /tmp/tmp4wmehv9f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 144M/144M [00:14<00:00, 9.93MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish download from http://212.129.155.247/fasthan/fasthan_base.zip\n",
            "Copy file to /root/.fastNLP/fasthan/fasthan_base\n",
            "loading vocabulary file /root/.fastNLP/fasthan/fasthan_base/vocab.txt\n",
            "Load pre-trained BERT parameters from file /root/.fastNLP/fasthan/fasthan_base/model.bin.\n",
            "Processing PyNLPIR ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 14:29:40 INFO: \"zh\" is an alias for \"zh-hans\"\n",
            "2021-05-22 14:29:40 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | gsdsimp |\n",
            "| pos       | gsdsimp |\n",
            "=======================\n",
            "\n",
            "2021-05-22 14:29:40 INFO: Use device: cpu\n",
            "2021-05-22 14:29:40 INFO: Loading: tokenize\n",
            "2021-05-22 14:29:40 INFO: Loading: pos\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing stanza ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 14:29:46 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing spacy ...\n",
            "\n",
            "Processing ltp ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6906a75a3b994bc2853b4f53ab3d565e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=164437832.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ltp/frontend.py:261: DeprecationWarning: Deprecated in 0.9.4: Encoding.words is deprecated, please use Encoding.word_ids instead.\n",
            "  ] for encoding in tokenized.encodings]\n",
            "/usr/local/lib/python3.7/dist-packages/ltp/frontend.py:260: DeprecationWarning: Deprecated in 0.9.4: Encoding.words is deprecated, please use Encoding.word_ids instead.\n",
            "  for idx, word_idx in enumerate(encoding.words) if word_idx is not None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing jiagu ...\n",
            "\n",
            "Processing lac ...\n",
            "\n",
            "Processing snownlp ...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPJXaJ6vjbpo"
      },
      "source": [
        "# Saving tagged words\n",
        "\n",
        "with open('/content/drive/MyDrive/data/words.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(words_tests, f, ensure_ascii=False) "
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXhz1OHQmYK"
      },
      "source": [
        "### Metrics on words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ_WTfCcm7-9"
      },
      "source": [
        "### How many splitted words into several?\n",
        "\n",
        "words_errors = {}\n",
        "for tool in pos_tools:\n",
        "    err = 0\n",
        "    for i in range(len(words_tests['fastHan'])):\n",
        "        try:\n",
        "            if len(words_tests[tool][i]) != 1:\n",
        "                err += 1\n",
        "        except:\n",
        "            err += 1\n",
        "    words_errors[tool] = err"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byt5FjPLo96f"
      },
      "source": [
        "write_to_stats(stat, 'words_errors', \n",
        "               pd.DataFrame(data=[words_errors, {k: v/N_words for k, v in words_errors.items()}], \n",
        "                            index=['absolute', 'mean']).reset_index())"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThNQnoaZtnJe"
      },
      "source": [
        "df_words = pd.DataFrame(words_tests)\n",
        "df_words['target'] = full.true_pos"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJICzi4-tzy0"
      },
      "source": [
        "def mostFreq(tool, df):\n",
        "\"\"\"\n",
        "Collect info of the most probable tag \n",
        "\"\"\"\n",
        "\n",
        "    most_freq = {}\n",
        "    for tags in ref_table[tool]:\n",
        "        for tag in tags:\n",
        "            if not tag in most_freq:\n",
        "                try:\n",
        "                    d = df[df[tool].apply(lambda x: tag in x)]['target'].value_counts()\n",
        "                    most_freq[tag] = (d.index[0], d[0])\n",
        "                except:\n",
        "                    for t, tar in zip(ref_table[tool], ref_table['fastHan']):\n",
        "                        if tag in t:\n",
        "                            most_freq[tag] = tar\n",
        "    return most_freq"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUntjkhSuA8b"
      },
      "source": [
        "# Get dictionary \n",
        "\n",
        "words_freq_dict = {i: {} for i in pos_tools}\n",
        "for tool in pos_tools:\n",
        "    if tool != 'fastHan':\n",
        "        words_freq_dict[tool] = mostFreq(tool, df_words)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjFE7S4fBTJA"
      },
      "source": [
        "## Compare tags\n",
        "\n",
        "def compare(REF, result, test, model, test_name, model_name='fastHan'):\n",
        "    \"\"\"\n",
        "    REF: reference tags table\n",
        "    result: where to write results\n",
        "    test: result of a tool\n",
        "    model: target\n",
        "\n",
        "    \"\"\"\n",
        "    idx = 0\n",
        "    count = 0\n",
        "    predict = []\n",
        "    errors = []\n",
        "    for m, t in tqdm(zip(model, test)):\n",
        "        idx += 1\n",
        "        try:\n",
        "            if isinstance(t, list):\n",
        "                for tag in t: \n",
        "                    new = tag\n",
        "                    if tag in REF[REF[model_name] == m][test_name].iloc[0]:\n",
        "                        new = m\n",
        "                        break\n",
        "                    else:\n",
        "                        new = tag\n",
        "                        errors.append((idx, m, t))\n",
        "            else:\n",
        "                if t in REF[REF[model_name] == m][test_name].iloc[0]:\n",
        "                    new = m\n",
        "                else:\n",
        "                    new = t\n",
        "                    errors.append((idx, m, t))\n",
        "            predict.append(new)\n",
        "        except:\n",
        "            errors.append((idx, m, t))\n",
        "            predict.append('')\n",
        "    predict = [i if i is not None else '' for i in predict]\n",
        "    result[test_name] = [accuracy_score(predict, model),\n",
        "                                precision_score(predict, model, average='macro'), \n",
        "                                recall_score(predict, model, average='macro'), \n",
        "                                f1_score(predict, model, average='macro'), \n",
        "                                errors]"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTlLQrks0V-N"
      },
      "source": [
        "words_results = pd.DataFrame(columns = pos_tools)\n",
        "# words_results.to_csv('/content/drive/MyDrive/data/words_results.csv') #checkpoint"
      ],
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4aO9nY12ps7"
      },
      "source": [
        ""
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZcbcbCujxKN"
      },
      "source": [
        "for tool in pos_tools:\n",
        "    print(f'\\nProcessing {tool}\\n')\n",
        "    compare(ref_table, words_results, words_tests[tool], df_words.target, tool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "W9-AXFbD_06Z",
        "outputId": "91061ac5-7fc7-4176-9cd0-099d1e392e2e"
      },
      "source": [
        "words_results"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ckiptagger</th>\n",
              "      <th>pkuseg</th>\n",
              "      <th>fastHan</th>\n",
              "      <th>PyNLPIR</th>\n",
              "      <th>stanza</th>\n",
              "      <th>spacy</th>\n",
              "      <th>ltp</th>\n",
              "      <th>jiagu</th>\n",
              "      <th>lac</th>\n",
              "      <th>snownlp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.674427</td>\n",
              "      <td>0.812007</td>\n",
              "      <td>0.74505</td>\n",
              "      <td>0.842438</td>\n",
              "      <td>0.80055</td>\n",
              "      <td>0.87516</td>\n",
              "      <td>0.815078</td>\n",
              "      <td>0.835564</td>\n",
              "      <td>0.835105</td>\n",
              "      <td>0.780339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.290183</td>\n",
              "      <td>0.362862</td>\n",
              "      <td>0.426926</td>\n",
              "      <td>0.230922</td>\n",
              "      <td>0.352938</td>\n",
              "      <td>0.444851</td>\n",
              "      <td>0.429876</td>\n",
              "      <td>0.356713</td>\n",
              "      <td>0.414455</td>\n",
              "      <td>0.302276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.416077</td>\n",
              "      <td>0.46772</td>\n",
              "      <td>0.494117</td>\n",
              "      <td>0.28866</td>\n",
              "      <td>0.550862</td>\n",
              "      <td>0.539844</td>\n",
              "      <td>0.568833</td>\n",
              "      <td>0.469697</td>\n",
              "      <td>0.553571</td>\n",
              "      <td>0.422535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.306982</td>\n",
              "      <td>0.390096</td>\n",
              "      <td>0.388543</td>\n",
              "      <td>0.250393</td>\n",
              "      <td>0.384092</td>\n",
              "      <td>0.474718</td>\n",
              "      <td>0.468394</td>\n",
              "      <td>0.387557</td>\n",
              "      <td>0.447759</td>\n",
              "      <td>0.331136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(10, M, [FW]), (11, NN, [FW]), (15, CD, [Neqa...</td>\n",
              "      <td>[(10, M, [n]), (16, VC, [v]), (18, M, [n]), (3...</td>\n",
              "      <td>[(5, DEC, [SP]), (6, NN, [JJ, NN]), (9, OD, [C...</td>\n",
              "      <td>[(10, M, [n]), (18, M, [n]), (40, SP, [ude1]),...</td>\n",
              "      <td>[(7, SB, [VERB]), (9, OD, [NUM]), (21, OD, [NU...</td>\n",
              "      <td>[(6, NN, [PROPN]), (7, SB, [X]), (9, OD, [NUM]...</td>\n",
              "      <td>[(10, M, [n]), (18, M, [n]), (24, DT, [d]), (2...</td>\n",
              "      <td>[(10, M, [n]), (16, VC, [vl]), (18, M, [n]), (...</td>\n",
              "      <td>[(6, NN, [a, n]), (10, M, [n]), (18, M, [n]), ...</td>\n",
              "      <td>[(1, NR, [j, Rg, Rg]), (1, NR, [j, Rg, Rg]), (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          ckiptagger  ...                                            snownlp\n",
              "0                                           0.674427  ...                                           0.780339\n",
              "1                                           0.290183  ...                                           0.302276\n",
              "2                                           0.416077  ...                                           0.422535\n",
              "3                                           0.306982  ...                                           0.331136\n",
              "4  [(10, M, [FW]), (11, NN, [FW]), (15, CD, [Neqa...  ...  [(1, NR, [j, Rg, Rg]), (1, NR, [j, Rg, Rg]), (...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbUV3ugd-KkC",
        "outputId": "a9928487-51c9-47fe-a146-28c0822bd7b5"
      },
      "source": [
        "## Get examples\n",
        "\n",
        "for tool in pos_tools:\n",
        "    print(f'Ошибки работы {tool}: ')\n",
        "    for i in range(10):\n",
        "        print(words_results[tool][4][i])\n",
        "    "
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ошибки работы ckiptagger: \n",
            "(10, 'M', ['FW'])\n",
            "(11, 'NN', ['FW'])\n",
            "(15, 'CD', ['Neqa'])\n",
            "(17, 'CD', ['FW'])\n",
            "(18, 'M', ['FW'])\n",
            "(22, 'NN', ['FW'])\n",
            "(25, 'CD', ['Neqa'])\n",
            "(26, 'CC', ['P'])\n",
            "(29, 'NN', ['FW'])\n",
            "(33, 'VV', ['FW'])\n",
            "Ошибки работы pkuseg: \n",
            "(10, 'M', ['n'])\n",
            "(16, 'VC', ['v'])\n",
            "(18, 'M', ['n'])\n",
            "(37, 'VC', ['v'])\n",
            "(42, 'AD', ['c'])\n",
            "(43, 'VC', ['v'])\n",
            "(46, 'VV', ['u', 'v'])\n",
            "(49, 'PN', ['c'])\n",
            "(62, 'VV', ['u'])\n",
            "(64, 'JJ', ['m'])\n",
            "Ошибки работы fastHan: \n",
            "(5, 'DEC', ['SP'])\n",
            "(6, 'NN', ['JJ', 'NN'])\n",
            "(9, 'OD', ['CD'])\n",
            "(10, 'M', ['NN'])\n",
            "(18, 'M', ['NN'])\n",
            "(19, 'DEG', ['SP'])\n",
            "(21, 'OD', ['CD'])\n",
            "(23, 'DEG', ['SP'])\n",
            "(24, 'DT', ['AD'])\n",
            "(26, 'CC', ['VV'])\n",
            "Ошибки работы PyNLPIR: \n",
            "(10, 'M', ['n'])\n",
            "(18, 'M', ['n'])\n",
            "(40, 'SP', ['ude1'])\n",
            "(42, 'AD', ['cc'])\n",
            "(46, 'VV', ['usuo', 'v'])\n",
            "(49, 'PN', ['rzv'])\n",
            "(59, 'NN', ['m'])\n",
            "(64, 'JJ', ['d'])\n",
            "(73, 'BA', ['v'])\n",
            "(76, 'VV', ['p'])\n",
            "Ошибки работы stanza: \n",
            "(7, 'SB', ['VERB'])\n",
            "(9, 'OD', ['NUM'])\n",
            "(21, 'OD', ['NUM'])\n",
            "(26, 'CC', ['ADP'])\n",
            "(28, 'P', ['VERB'])\n",
            "(30, 'LC', ['NOUN'])\n",
            "(32, 'SB', ['VERB'])\n",
            "(35, 'PU', ['NOUN'])\n",
            "(46, 'VV', ['ADV', 'VERB'])\n",
            "(50, 'LC', ['NOUN'])\n",
            "Ошибки работы spacy: \n",
            "(6, 'NN', ['PROPN'])\n",
            "(7, 'SB', ['X'])\n",
            "(9, 'OD', ['NUM'])\n",
            "(21, 'OD', ['NUM'])\n",
            "(24, 'DT', ['ADV'])\n",
            "(32, 'SB', ['X'])\n",
            "(46, 'VV', ['PART', 'VERB'])\n",
            "(49, 'PN', ['ADV'])\n",
            "(54, 'OD', ['NUM'])\n",
            "(59, 'NN', ['NUM'])\n",
            "Ошибки работы ltp: \n",
            "(10, 'M', ['n'])\n",
            "(18, 'M', ['n'])\n",
            "(24, 'DT', ['d'])\n",
            "(26, 'CC', ['nh'])\n",
            "(30, 'LC', ['j'])\n",
            "(42, 'AD', ['c'])\n",
            "(46, 'VV', ['u'])\n",
            "(48, 'P', ['v'])\n",
            "(49, 'PN', ['c'])\n",
            "(59, 'NN', ['m'])\n",
            "Ошибки работы jiagu: \n",
            "(10, 'M', ['n'])\n",
            "(16, 'VC', ['vl'])\n",
            "(18, 'M', ['n'])\n",
            "(35, 'PU', ['n'])\n",
            "(37, 'VC', ['vl'])\n",
            "(42, 'AD', ['c'])\n",
            "(43, 'VC', ['vl'])\n",
            "(50, 'LC', ['nt'])\n",
            "(72, 'LC', ['nt'])\n",
            "(84, 'AD', ['a'])\n",
            "Ошибки работы lac: \n",
            "(6, 'NN', ['a', 'n'])\n",
            "(10, 'M', ['n'])\n",
            "(18, 'M', ['n'])\n",
            "(26, 'CC', ['p'])\n",
            "(28, 'P', ['v'])\n",
            "(42, 'AD', ['c'])\n",
            "(64, 'JJ', ['n'])\n",
            "(81, 'LC', ['v'])\n",
            "(84, 'AD', ['a'])\n",
            "(88, 'CD', ['n'])\n",
            "Ошибки работы snownlp: \n",
            "(1, 'NR', ['j', 'Rg', 'Rg'])\n",
            "(1, 'NR', ['j', 'Rg', 'Rg'])\n",
            "(1, 'NR', ['j', 'Rg', 'Rg'])\n",
            "(10, 'M', ['n'])\n",
            "(14, 'VE', ['v'])\n",
            "(30, 'LC', ['j'])\n",
            "(40, 'SP', ['u'])\n",
            "(42, 'AD', ['c'])\n",
            "(46, 'VV', ['u', 'v'])\n",
            "(59, 'NN', ['m'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZAXqHsWQfwT"
      },
      "source": [
        "## Comparison by sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kYjwwGsTj6_"
      },
      "source": [
        "full['id_sent'] = full.id_sent.apply(int)"
      ],
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BT0Pip4T4tK"
      },
      "source": [
        "sentences = full.groupby(['nickname', 'id_sent']).agg({'token':lambda x: list(x),\n",
        "                                                      'pos': lambda x: list(x), \n",
        "                                                      'id_token': lambda x: list(x)})\n",
        "sentences['id_sent'] = [i[1] for i in sentences.index]\n"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9qf1G8Bu1I"
      },
      "source": [
        "def get_index(inp):\n",
        "    lst = [[] for i in inp]\n",
        "    count = 0\n",
        "    for k, word in enumerate(inp):\n",
        "        lst[k] = [count+i for i in range(len(word))]\n",
        "        count+= len(word)\n",
        "    return lst"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "JUuyqIJ3CIUo",
        "outputId": "7b99792d-a1b4-4491-d9cf-d37eac95d916"
      },
      "source": [
        "sentences.head()"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>pos</th>\n",
              "      <th>id_token</th>\n",
              "      <th>id_sent</th>\n",
              "      <th>sent</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nickname</th>\n",
              "      <th>id_sent</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">gold2_125</th>\n",
              "      <th>0</th>\n",
              "      <td>[洛什卡列夫, 一, 家, 住, 的, 简易房, 被, 叫做, 三, 号, 楼, ，, 它,...</td>\n",
              "      <td>[NR, CD, NN, VV, DEC, NN, SB, VV, OD, M, NN, P...</td>\n",
              "      <td>[[0, 1, 2, 3, 4], [5], [6], [7], [8], [9, 10, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>洛什卡列夫一家住的简易房被叫做三号楼，它有一半是两层的，二楼的另一半和楼梯在战争中就被毁了—...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[从, 那, 以后, ，, 要, 到, 二, 楼, 剩, 下来, 的, 部分, 去, 就, ...</td>\n",
              "      <td>[P, PN, LC, PU, VV, VV, OD, NN, VV, VV, DEC, N...</td>\n",
              "      <td>[[0], [1], [2, 3], [4], [5], [6], [7], [8], [9...</td>\n",
              "      <td>1</td>\n",
              "      <td>从那以后，要到二楼剩下来的部分去就得爬单梯。洛什卡列夫从军队医院回来之后把这梯子给加固了。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[脚, 下, 的, 路面, 微微, 发亮, 。]</td>\n",
              "      <td>[NN, LC, DEG, NN, AD, VV, PU]</td>\n",
              "      <td>[[0], [1], [2], [3, 4], [5, 6], [7, 8], [9]]</td>\n",
              "      <td>2</td>\n",
              "      <td>脚下的路面微微发亮。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[这, 部分, 城郊, 当时, 还, 很, 偏僻, ，, 没有, 多少, 房屋, ，, 遍地...</td>\n",
              "      <td>[DT, CD, NN, NT, AD, AD, VA, PU, VE, CD, NN, P...</td>\n",
              "      <td>[[0], [1, 2], [3, 4], [5, 6], [7], [8], [9, 10...</td>\n",
              "      <td>3</td>\n",
              "      <td>这部分城郊当时还很偏僻，没有多少房屋，遍地是杂草。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[她, 的, 瞳孔, 睁, 得, 这么, 大, ，, 几乎, 和, 黑色, 的, 虹膜圈, ...</td>\n",
              "      <td>[PN, DEG, NN, VV, DER, AD, VA, PU, AD, P, JJ, ...</td>\n",
              "      <td>[[0], [1], [2, 3], [4], [5], [6, 7], [8], [9],...</td>\n",
              "      <td>4</td>\n",
              "      <td>她的瞳孔睁得这么大，几乎和黑色的虹膜圈合在一起了，而且眼睛显得不是灰色的，而是黑色的。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                               token  ...                                               sent\n",
              "nickname  id_sent                                                     ...                                                   \n",
              "gold2_125 0        [洛什卡列夫, 一, 家, 住, 的, 简易房, 被, 叫做, 三, 号, 楼, ，, 它,...  ...  洛什卡列夫一家住的简易房被叫做三号楼，它有一半是两层的，二楼的另一半和楼梯在战争中就被毁了—...\n",
              "          1        [从, 那, 以后, ，, 要, 到, 二, 楼, 剩, 下来, 的, 部分, 去, 就, ...  ...      从那以后，要到二楼剩下来的部分去就得爬单梯。洛什卡列夫从军队医院回来之后把这梯子给加固了。\n",
              "          2                                 [脚, 下, 的, 路面, 微微, 发亮, 。]  ...                                         脚下的路面微微发亮。\n",
              "          3        [这, 部分, 城郊, 当时, 还, 很, 偏僻, ，, 没有, 多少, 房屋, ，, 遍地...  ...                          这部分城郊当时还很偏僻，没有多少房屋，遍地是杂草。\n",
              "          4        [她, 的, 瞳孔, 睁, 得, 这么, 大, ，, 几乎, 和, 黑色, 的, 虹膜圈, ...  ...        她的瞳孔睁得这么大，几乎和黑色的虹膜圈合在一起了，而且眼睛显得不是灰色的，而是黑色的。\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a0tkNdcbvf_",
        "outputId": "b5fe0130-e36b-48b5-a185-59063e4776ca"
      },
      "source": [
        "sentences['id_token'] = sentences.token.progress_apply(get_index)"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1036/1036 [00:00<00:00, 25823.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS3WIzp8U84o"
      },
      "source": [
        "sentences['sent'] = sentences.token.apply(lambda x: ''.join(x))\n",
        "sent_tests = {}"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAFPj1RLEgbq"
      },
      "source": [
        "import time"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d98dojaQUv9"
      },
      "source": [
        "# col_sents = ['words', 'pos', 'indices']\n",
        "\n",
        "def run_tools_sent(tool): # by words segmented previously by fasthan\n",
        "    print(f'Preprocessing with {tool}...', '\\n')\n",
        "    if tool == 'ckiptagger':\n",
        "        from ckiptagger import data_utils, WS, POS\n",
        "        ws = WS('/content/drive/MyDrive/data/ckiptagger')\n",
        "        pos = POS(\"/content/drive/My Drive/data/ckiptagger\")\n",
        "        words = ws(sentences.sent)\n",
        "        start_time = time.clock()\n",
        "        pos_tags = pos(words)\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]\n",
        "\n",
        "    if tool == 'pkuseg':\n",
        "        seg = pkuseg.pkuseg(postag=True)\n",
        "        pos_tags = []\n",
        "        words = []\n",
        "        start_time = time.clock()\n",
        "\n",
        "        for sent in tqdm(sentences.sent):\n",
        "            try:\n",
        "                text = seg.cut(sent)\n",
        "                pos_tags.append([i[1] for i in text])\n",
        "                words.append([i[0] for i in text])\n",
        "            except IndexError:\n",
        "                pos_tags.append([''])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]\n",
        "\n",
        "    if tool == 'PyNLPIR':\n",
        "        pynlpir.open()\n",
        "        pos_tags = []\n",
        "        words = []      \n",
        "        start_time = time.clock()  \n",
        "        for sent in sentences.sent:\n",
        "            try:\n",
        "                text = pynlpir.segment(sent, pos_names='raw')\n",
        "                words.append([i[0] for i in text])\n",
        "                pos_tags.append([i[1] for i in text])\n",
        "            except:\n",
        "                pos_tags.append([''])\n",
        "                words.append([''])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]\n",
        "        pynlpir.close()\n",
        "\n",
        "    if tool == 'stanza':\n",
        "        nlp = stanza.Pipeline('zh', processors='tokenize, pos')\n",
        "        pos_tags = []\n",
        "        words = []\n",
        "        xpos = []\n",
        "        start_time = time.clock()\n",
        "        for word in sentences.sent:\n",
        "            doc = nlp(word)\n",
        "            pos_tags.append([word.upos for sent in doc.sentences for word in sent.words])\n",
        "            xpos.append([word.xpos for sent in doc.sentences for word in sent.words])\n",
        "            words.append([word.text for sent in doc.sentences for word in sent.words])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent), xpos]\n",
        "\n",
        "\n",
        "    if tool == 'spacy':\n",
        "        nlp = zh_core_web_sm.load()\n",
        "        pos_tags = []\n",
        "        words = []\n",
        "        xpos = []\n",
        "        start_time = time.clock()\n",
        "        for word in sentences.sent:\n",
        "            doc = nlp(word)\n",
        "            pos_tags.append([word.pos_ for word in doc])\n",
        "            xpos.append([word.tag_ for word in doc])\n",
        "            words.append([word.text for word in doc])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent), xpos]\n",
        "\n",
        "    if tool == 'ltp':\n",
        "        ltp = LTP()\n",
        "        seg, hidden = ltp.seg(sentences.sent.tolist())\n",
        "        pos = ltp.pos(hidden)\n",
        "        words = []\n",
        "        pos_tags = []\n",
        "        start_time = time.clock()\n",
        "        for i in range(len(seg)):\n",
        "            pos_tags.append([word for word in pos[i]])\n",
        "            words.append([word for word in seg[i]])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]\n",
        "\n",
        "    if tool == 'jiagu':\n",
        "        pos_tags = []\n",
        "        words = []\n",
        "        start_time = time.clock()\n",
        "        for sent in sentences.sent:\n",
        "            try:\n",
        "                seg = jiagu.seg(sent)\n",
        "                pos_tags.append(jiagu.pos(seg))\n",
        "                words.append(seg)\n",
        "            except:\n",
        "                pos_tags.append([''])\n",
        "                words.append([''])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]\n",
        "\n",
        "    if tool == 'lac':\n",
        "        lac = LAC(mode='rank')\n",
        "        pos_tags = []\n",
        "        words = []\n",
        "        start_time = time.clock()\n",
        "        for sent in sentences.sent:\n",
        "            doc = lac.run(sent)\n",
        "            try:\n",
        "                pos_tags.append(doc[1])\n",
        "                words.append(doc[0])\n",
        "            except:\n",
        "                pos_tags.append([''])\n",
        "                words.append([''])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]\n",
        "\n",
        "    if tool == 'snownlp':\n",
        "        pos_tags = []\n",
        "        words = []\n",
        "        start_time = time.clock()\n",
        "        for sent in sentences.sent:\n",
        "            # doc = SnowNLP(sent).tags\n",
        "            try:\n",
        "                pos_tags.append([i[1] for i in SnowNLP(sent).tags])\n",
        "                words.append([i[0] for i in SnowNLP(sent).tags])\n",
        "            except:\n",
        "                words.append([''])\n",
        "                pos_tags.append([''])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]\n",
        "\n",
        "    if tool == 'fastHan':\n",
        "        model=FastHan()\n",
        "        words = []\n",
        "        pos_tags = []\n",
        "        start_time = time.clock()\n",
        "        for sent in sentences.sent:\n",
        "            doc = model(sent, target=\"Parsing\")[0]\n",
        "            pos_tags.append([tag[3] for tag in doc])\n",
        "            words.append([tag[0] for tag in doc])\n",
        "        print(f'Время выполнения: {time.clock() - start_time}')\n",
        "        sent_tests[tool] = [words, pos_tags, list(sentences.id_sent)]"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2m4iXNMkCoU",
        "outputId": "5c719f38-016b-4898-b850-fe06c6256094"
      },
      "source": [
        "for tool in pos_tools:\n",
        "    run_tools_sent(tool)"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing with ckiptagger... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "\n",
            "\n",
            "21092it [1:12:33,  4.84it/s]\n",
            "6022it [48:10,  2.08it/s] \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 45.717923000000155\n",
            "Preprocessing with pkuseg... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            " 97%|█████████▋| 1003/1036 [00:01<00:00, 625.25it/s]\n",
            "100%|██████████| 1036/1036 [00:01<00:00, 567.91it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 1.8266349999998965\n",
            "Preprocessing with fastHan... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 696/1036 [09:40<00:01, 170.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loading vocabulary file /root/.fastNLP/fasthan/fasthan_base/vocab.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 696/1036 [09:41<00:01, 170.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load pre-trained BERT parameters from file /root/.fastNLP/fasthan/fasthan_base/model.bin.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:141: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 156.4073410000001\n",
            "Preprocessing with PyNLPIR... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "2021-05-22 17:23:53 INFO: \"zh\" is an alias for \"zh-hans\"\n",
            "2021-05-22 17:23:53 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | gsdsimp |\n",
            "| pos       | gsdsimp |\n",
            "=======================\n",
            "\n",
            "2021-05-22 17:23:53 INFO: Use device: cpu\n",
            "2021-05-22 17:23:53 INFO: Loading: tokenize\n",
            "2021-05-22 17:23:53 INFO: Loading: pos\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 0.3600859999996828\n",
            "Preprocessing with stanza... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 17:23:59 INFO: Done loading processors!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 41.30156699999998\n",
            "Preprocessing with spacy... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 10.520791999999801\n",
            "Preprocessing with ltp... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ltp/frontend.py:261: DeprecationWarning: Deprecated in 0.9.4: Encoding.words is deprecated, please use Encoding.word_ids instead.\n",
            "  ] for encoding in tokenized.encodings]\n",
            "/usr/local/lib/python3.7/dist-packages/ltp/frontend.py:260: DeprecationWarning: Deprecated in 0.9.4: Encoding.words is deprecated, please use Encoding.word_ids instead.\n",
            "  for idx, word_idx in enumerate(encoding.words) if word_idx is not None\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:88: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:94: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 0.004472999999961758\n",
            "Preprocessing with jiagu... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:103: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 4.502116000000115\n",
            "Preprocessing with lac... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:119: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Время выполнения: 2.8567549999997937\n",
            "Preprocessing with snownlp... \n",
            "\n",
            "Время выполнения: 41.6698779999997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:134: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6rsLO_2Us2"
      },
      "source": [
        "# with open('/content/drive/MyDrive/data/sentences.json', 'w', encoding='utf-8') as f:\n",
        "#     json.dump(sent_tests, f, ensure_ascii=False)"
      ],
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efZpT0xjv3KG"
      },
      "source": [
        "# with open('/content/drive/MyDrive/data/sentences.json') as f:\n",
        "    # sent_tests = json.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KChhQN_6ASD8"
      },
      "source": [
        "chars = [] # all characters in a row\n",
        "for token in full.token:\n",
        "    for char in list(token):\n",
        "        chars.append(char)"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1chg6ALeS7zs"
      },
      "source": [
        "def squeeze(sentences): # tags for each char\n",
        "    lst_char = []\n",
        "    sents, pos_tags = sentences[0], sentences[1]\n",
        "\n",
        "    for k1, sent in enumerate(sents):\n",
        "        for k2, word in enumerate(sent):\n",
        "            for k3, char in enumerate(list(word)):\n",
        "                lst_char.append(pos_tags[k1][k2])\n",
        "\n",
        "    return lst_char\n"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AmbcvJWGPK7"
      },
      "source": [
        "## true tags in a row\n",
        "\n",
        "true = []\n",
        "sent = [] # sent_ids\n",
        "for i, token in enumerate(full.token):\n",
        "    for char in token:\n",
        "        true.append(full.true_pos[i])\n",
        "        sent.append(full.id_sent[i])"
      ],
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CenoUA16-q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeefb97c-7611-4127-f00a-1253445a76bc"
      },
      "source": [
        "df_char = pd.DataFrame(columns = pos_tools)\n",
        "for tool in pos_tools:\n",
        "    print(tool)\n",
        "    df_char[tool] = squeeze(sent_tests[tool])"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ckiptagger\n",
            "pkuseg\n",
            "fastHan\n",
            "PyNLPIR\n",
            "stanza\n",
            "spacy\n",
            "ltp\n",
            "jiagu\n",
            "lac\n",
            "snownlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05JgVjlC6Tk_"
      },
      "source": [
        "df_char['target'] = true\n",
        "df_char['char'] = chars\n",
        "df_char['sent'] = sent"
      ],
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "5Sz00sWyMQD3",
        "outputId": "563e061d-5685-471b-aa2f-97e776140aa0"
      },
      "source": [
        "df_char.head()"
      ],
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ckiptagger</th>\n",
              "      <th>pkuseg</th>\n",
              "      <th>fastHan</th>\n",
              "      <th>PyNLPIR</th>\n",
              "      <th>stanza</th>\n",
              "      <th>spacy</th>\n",
              "      <th>ltp</th>\n",
              "      <th>jiagu</th>\n",
              "      <th>lac</th>\n",
              "      <th>snownlp</th>\n",
              "      <th>target</th>\n",
              "      <th>char</th>\n",
              "      <th>sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nb</td>\n",
              "      <td>nr</td>\n",
              "      <td>NR</td>\n",
              "      <td>nrf</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nh</td>\n",
              "      <td>nh</td>\n",
              "      <td>PER</td>\n",
              "      <td>j</td>\n",
              "      <td>NR</td>\n",
              "      <td>洛</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nb</td>\n",
              "      <td>nr</td>\n",
              "      <td>NR</td>\n",
              "      <td>nrf</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nh</td>\n",
              "      <td>m</td>\n",
              "      <td>PER</td>\n",
              "      <td>nz</td>\n",
              "      <td>NR</td>\n",
              "      <td>什</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nb</td>\n",
              "      <td>nr</td>\n",
              "      <td>NR</td>\n",
              "      <td>nrf</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nh</td>\n",
              "      <td>n</td>\n",
              "      <td>PER</td>\n",
              "      <td>nz</td>\n",
              "      <td>NR</td>\n",
              "      <td>卡</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nb</td>\n",
              "      <td>nr</td>\n",
              "      <td>NR</td>\n",
              "      <td>nrf</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nh</td>\n",
              "      <td>v</td>\n",
              "      <td>PER</td>\n",
              "      <td>nx</td>\n",
              "      <td>NR</td>\n",
              "      <td>列</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nb</td>\n",
              "      <td>nr</td>\n",
              "      <td>NR</td>\n",
              "      <td>nrf</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nh</td>\n",
              "      <td>n</td>\n",
              "      <td>PER</td>\n",
              "      <td>nx</td>\n",
              "      <td>NR</td>\n",
              "      <td>夫</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ckiptagger pkuseg fastHan PyNLPIR stanza  ...  lac snownlp target char sent\n",
              "0         Nb     nr      NR     nrf  PROPN  ...  PER       j     NR    洛    0\n",
              "1         Nb     nr      NR     nrf  PROPN  ...  PER      nz     NR    什    0\n",
              "2         Nb     nr      NR     nrf  PROPN  ...  PER      nz     NR    卡    0\n",
              "3         Nb     nr      NR     nrf  PROPN  ...  PER      nx     NR    列    0\n",
              "4         Nb     nr      NR     nrf  PROPN  ...  PER      nx     NR    夫    0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKy1Vfl4FzUE"
      },
      "source": [
        "ref_char = pd.DataFrame(columns=pos_tools) # create table with results\n",
        "\n",
        "def compare_char(REF, test, model, test_name, model_name='fastHan'):\n",
        "    idx = 0\n",
        "    count = 0\n",
        "    predict = []\n",
        "    errors = []\n",
        "    for m, t in tqdm(zip(model, test)):\n",
        "        if t != '':\n",
        "            try:\n",
        "                if t in REF[REF[model_name] == m][test_name].iloc[0]:\n",
        "                    new = m\n",
        "                else:\n",
        "                    new = t\n",
        "                    errors.append((idx, m, t))\n",
        "            except IndexError:\n",
        "                new = t\n",
        "        else:\n",
        "            new = t\n",
        "        predict.append(new)\n",
        "\n",
        "    ref_char[test_name] = predict"
      ],
      "execution_count": 535,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7evaFCEaKmci"
      },
      "source": [
        "for tool in pos_tools:\n",
        "    print(tool)\n",
        "    compare_char(ref_table, df_char[tool], df_char['target'], tool)\n",
        "ref_char['target'] = true\n",
        "ref_char['char'] = df_char.char"
      ],
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yAdUiGE46-dU",
        "outputId": "d4e0ec4c-0032-4d3e-a5d0-e8b3e28d0cf6"
      },
      "source": [
        "ref_char[ref_char.target == 'PU'][ref_char.ltp != 'PU']"
      ],
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ckiptagger</th>\n",
              "      <th>pkuseg</th>\n",
              "      <th>fastHan</th>\n",
              "      <th>PyNLPIR</th>\n",
              "      <th>stanza</th>\n",
              "      <th>spacy</th>\n",
              "      <th>ltp</th>\n",
              "      <th>jiagu</th>\n",
              "      <th>lac</th>\n",
              "      <th>snownlp</th>\n",
              "      <th>target</th>\n",
              "      <th>char</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3177</th>\n",
              "      <td>I</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>z</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>“</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3955</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>VERB</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Bg</td>\n",
              "      <td>PU</td>\n",
              "      <td>…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3956</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PART</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Bg</td>\n",
              "      <td>PU</td>\n",
              "      <td>…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3957</th>\n",
              "      <td>P</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Bg</td>\n",
              "      <td>PU</td>\n",
              "      <td>”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6291</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>b</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6292</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>b</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6872</th>\n",
              "      <td>VE</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>d</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9356</th>\n",
              "      <td>Na</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>n</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>·</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11310</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11311</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12287</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>i</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>，</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14019</th>\n",
              "      <td>Nb</td>\n",
              "      <td>PU</td>\n",
              "      <td>NN</td>\n",
              "      <td>m</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>①</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14539</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>e</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14540</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>e</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14949</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>VERB</td>\n",
              "      <td>PU</td>\n",
              "      <td>d</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14950</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>VERB</td>\n",
              "      <td>PU</td>\n",
              "      <td>d</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14973</th>\n",
              "      <td>Neu</td>\n",
              "      <td>j</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ns</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>①</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16656</th>\n",
              "      <td>Neu</td>\n",
              "      <td>PU</td>\n",
              "      <td>NN</td>\n",
              "      <td>m</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>nw</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>③</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16662</th>\n",
              "      <td>Neu</td>\n",
              "      <td>PU</td>\n",
              "      <td>CD</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>NUM</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>nw</td>\n",
              "      <td>b</td>\n",
              "      <td>PU</td>\n",
              "      <td>③</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16699</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18797</th>\n",
              "      <td>FW</td>\n",
              "      <td>n</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nz</td>\n",
              "      <td>PU</td>\n",
              "      <td>n</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>①</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18800</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18801</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18802</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18803</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18804</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18805</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18806</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18807</th>\n",
              "      <td>FW</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18808</th>\n",
              "      <td>FW</td>\n",
              "      <td>PU</td>\n",
              "      <td>NN</td>\n",
              "      <td>m</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>m</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>①</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18819</th>\n",
              "      <td>FW</td>\n",
              "      <td>nr</td>\n",
              "      <td>PU</td>\n",
              "      <td>rzt</td>\n",
              "      <td>PU</td>\n",
              "      <td>PRON</td>\n",
              "      <td>ws</td>\n",
              "      <td>n</td>\n",
              "      <td>xc</td>\n",
              "      <td>na</td>\n",
              "      <td>PU</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20017</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20018</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22875</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>n</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22876</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>VERB</td>\n",
              "      <td>PU</td>\n",
              "      <td>n</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23299</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>nh</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>，</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23338</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PU</td>\n",
              "      <td>nh</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23339</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>nh</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25095</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>p</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25096</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>p</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25097</th>\n",
              "      <td>VG</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>p</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25291</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25292</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>—</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26817</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>p</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26818</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>p</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26819</th>\n",
              "      <td>VG</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>p</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28712</th>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>nh</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>a</td>\n",
              "      <td>PU</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29088</th>\n",
              "      <td>Neu</td>\n",
              "      <td>n</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>PART</td>\n",
              "      <td>NUM</td>\n",
              "      <td>n</td>\n",
              "      <td>PU</td>\n",
              "      <td>m</td>\n",
              "      <td>vd</td>\n",
              "      <td>PU</td>\n",
              "      <td>④</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29302</th>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>v</td>\n",
              "      <td>PU</td>\n",
              "      <td>PU</td>\n",
              "      <td>Rg</td>\n",
              "      <td>PU</td>\n",
              "      <td>。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ckiptagger pkuseg fastHan PyNLPIR stanza  ... jiagu lac snownlp target char\n",
              "3177           I     PU      PU      PU     PU  ...    PU  PU      PU     PU    “\n",
              "3955          PU     PU      PU      PU   VERB  ...    PU  PU      Bg     PU    …\n",
              "3956          PU     PU      PU      PU   PART  ...    PU  PU      Bg     PU    …\n",
              "3957           P     PU      PU      PU     PU  ...    PU  PU      Bg     PU    ”\n",
              "6291          PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "6292          PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "6872          VE     PU      PU      PU     PU  ...    PU  PU      PU     PU    ”\n",
              "9356          Na     PU      PU      PU     PU  ...    PU  PU      PU     PU    ·\n",
              "11310         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "11311         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "12287         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    ，\n",
              "14019         Nb     PU      NN       m  PROPN  ...    PU  PU      PU     PU    ①\n",
              "14539         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "14540         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "14949         PU     PU      PU      PU   VERB  ...    PU  PU      PU     PU    —\n",
              "14950         PU     PU      PU      PU   VERB  ...    PU  PU      PU     PU    —\n",
              "14973        Neu      j      PU       m   NOUN  ...    PU   m       m     PU    ①\n",
              "16656        Neu     PU      NN       m   NOUN  ...    PU  nw      Rg     PU    ③\n",
              "16662        Neu     PU      CD       m     PU  ...    PU  nw       b     PU    ③\n",
              "16699         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "18797         FW      n      PU       m     PU  ...    PU   n      Rg     PU    ①\n",
              "18800         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18801         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18802         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18803         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18804         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18805         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18806         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18807         FW      v      PU      PU     PU  ...    PU  PU      Rg     PU    -\n",
              "18808         FW     PU      NN       m  PROPN  ...    PU  PU      Rg     PU    ①\n",
              "18819         FW     nr      PU     rzt     PU  ...     n  xc      na     PU    I\n",
              "20017         PU     PU      PU      PU   NOUN  ...    PU  PU      PU     PU    —\n",
              "20018         PU     PU      PU      PU   NOUN  ...    PU  PU      PU     PU    —\n",
              "22875         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "22876         PU     PU      PU      PU   VERB  ...    PU  PU      PU     PU    —\n",
              "23299         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    ，\n",
              "23338         PU     PU      PU      PU  PROPN  ...    PU  PU      PU     PU    —\n",
              "23339         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "25095         PU     PU      PU      PU     PU  ...    PU  PU      Rg     PU    …\n",
              "25096         PU     PU      PU      PU     PU  ...    PU  PU      Rg     PU    …\n",
              "25097         VG     PU      PU      PU     PU  ...    PU  PU      Rg     PU    ”\n",
              "25291         PU     PU      PU      PU   NOUN  ...    PU  PU      PU     PU    —\n",
              "25292         PU     PU      PU      PU     PU  ...    PU  PU      PU     PU    —\n",
              "26817         PU     PU      PU      PU     PU  ...    PU  PU      Rg     PU    …\n",
              "26818         PU     PU      PU      PU     PU  ...    PU  PU      Rg     PU    …\n",
              "26819         VG     PU      PU      PU     PU  ...    PU  PU      Rg     PU    ”\n",
              "28712         PU      v      PU      PU     PU  ...    PU  PU       a     PU    ?\n",
              "29088        Neu      n      PU       m   PART  ...    PU   m      vd     PU    ④\n",
              "29302         PU     PU      PU      PU     PU  ...    PU  PU      Rg     PU    。\n",
              "\n",
              "[49 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJt91KBy_ONE"
      },
      "source": [
        "# ref_char.to_csv('/content/drive/MyDrive/data/ref_char.csv', sep='\\t')\n",
        "# df_char.to_csv('/content/drive/MyDrive/data/df_char.csv', sep='\\t')"
      ],
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ0u1q7UVX16",
        "outputId": "5127fbdf-fd03-4369-d4cc-75ae8ed011d8"
      },
      "source": [
        "res_sents = pd.DataFrame(columns=pos_tools, index=['accuracy', 'precision', 'recall', 'f1_score'])\n",
        "for tool in pos_tools:\n",
        "    res_sents[tool] = [accuracy_score(ref_char[tool], ref_char.target),\n",
        "                                precision_score(ref_char[tool], ref_char.target, average='macro'), \n",
        "                                recall_score(ref_char[tool], ref_char.target, average='macro'), \n",
        "                                f1_score(ref_char[tool], ref_char.target, average='macro')]"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNM-AVgmaFOo"
      },
      "source": [
        "# res_sents.to_csv('/content/drive/MyDrive/data/res_sents.csv')\n",
        "# res_sents = pd.read_csv('/content/drive/MyDrive/data/res_sents.csv')"
      ],
      "execution_count": 559,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "CIg97DRSQHnO",
        "outputId": "96ff4db7-ae62-44af-8d1c-afe4daae01fe"
      },
      "source": [
        "res_sents # Preliminar results"
      ],
      "execution_count": 560,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ckiptagger</th>\n",
              "      <th>pkuseg</th>\n",
              "      <th>fastHan</th>\n",
              "      <th>PyNLPIR</th>\n",
              "      <th>stanza</th>\n",
              "      <th>spacy</th>\n",
              "      <th>ltp</th>\n",
              "      <th>jiagu</th>\n",
              "      <th>lac</th>\n",
              "      <th>snownlp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.663670</td>\n",
              "      <td>0.827700</td>\n",
              "      <td>0.976035</td>\n",
              "      <td>0.830801</td>\n",
              "      <td>0.807024</td>\n",
              "      <td>0.871558</td>\n",
              "      <td>0.819053</td>\n",
              "      <td>0.780865</td>\n",
              "      <td>0.847373</td>\n",
              "      <td>0.703267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.276166</td>\n",
              "      <td>0.388939</td>\n",
              "      <td>0.899176</td>\n",
              "      <td>0.223502</td>\n",
              "      <td>0.419430</td>\n",
              "      <td>0.443491</td>\n",
              "      <td>0.451724</td>\n",
              "      <td>0.369516</td>\n",
              "      <td>0.430320</td>\n",
              "      <td>0.273940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recall</td>\n",
              "      <td>0.379683</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.919571</td>\n",
              "      <td>0.271930</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f1_score</td>\n",
              "      <td>0.290562</td>\n",
              "      <td>0.424474</td>\n",
              "      <td>0.907689</td>\n",
              "      <td>0.243067</td>\n",
              "      <td>0.468110</td>\n",
              "      <td>0.484565</td>\n",
              "      <td>0.496496</td>\n",
              "      <td>0.410596</td>\n",
              "      <td>0.468906</td>\n",
              "      <td>0.309400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ckiptagger    pkuseg  ...     jiagu       lac   snownlp\n",
              "0   accuracy    0.663670  0.827700  ...  0.780865  0.847373  0.703267\n",
              "1  precision    0.276166  0.388939  ...  0.369516  0.430320  0.273940\n",
              "2     recall    0.379683  0.500000  ...  0.515625  0.551724  0.384615\n",
              "3   f1_score    0.290562  0.424474  ...  0.410596  0.468906  0.309400\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 560
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrlXARWZQK4P"
      },
      "source": [
        "### Replace wrong tags by the most frequent match\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnOryR0IQKan"
      },
      "source": [
        "## наиболее вероятное значение тега\n",
        "def mostFreq(tool):\n",
        "    most_freq = {}\n",
        "    for tags in ref_table[tool]:\n",
        "        for tag in tags:\n",
        "            if not tag in most_freq:\n",
        "                try:\n",
        "                    most_freq[tag] = df_char[df_char[tool] == tag]['target'].value_counts().index[0]\n",
        "                except:\n",
        "                    for t, tar in zip(ref_table[tool], ref_table['fastHan']):\n",
        "                        if tag in t:\n",
        "                            most_freq[tag] = tar\n",
        "    return most_freq"
      ],
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwfhUXrpQhGo"
      },
      "source": [
        "mostFreqDict = {i: {} for i in pos_tools}\n",
        "for tool in pos_tools:\n",
        "    mostFreqDict[tool] = mostFreq(tool)"
      ],
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYGxIpqJQhGz",
        "outputId": "2061f829-3da8-400c-a13a-3129c63d85ec"
      },
      "source": [
        "### Replace\n",
        "for tool in pos_tools:\n",
        "    print(tool)\n",
        "    for k, pair in enumerate(zip(ref_char[tool], ref_char.target)):\n",
        "        tag, tar = pair[0], pair[1]\n",
        "        if tag != tar:\n",
        "            if tag not in mostFreqDict[tool]:\n",
        "                continue\n",
        "            else:\n",
        "                ref_char[tool][k] = mostFreqDict[tool][tag]"
      ],
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ckiptagger\n",
            "pkuseg\n",
            "fastHan\n",
            "PyNLPIR\n",
            "stanza\n",
            "spacy\n",
            "ltp\n",
            "jiagu\n",
            "lac\n",
            "snownlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N9wPUlzjjGa"
      },
      "source": [
        "# with open('/content/drive/MyDrive/data/frequent_replacement.json', 'w', encoding='utf-8') as f:\n",
        "#     json.dump(mostFreqDict, f, ensure_ascii=False)"
      ],
      "execution_count": 548,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrvjsLoYStrN",
        "outputId": "7595fd15-e671-4fb2-9b55-65fe4ea95b0a"
      },
      "source": [
        "## Results after replacement\n",
        "res_sents = pd.DataFrame(columns=pos_tools, index=['accuracy', 'precision', 'recall', 'f1_score'])\n",
        "for tool in pos_tools:\n",
        "    res_sents[tool] = [accuracy_score(ref_char[tool], ref_char.target),\n",
        "                                precision_score(ref_char[tool], ref_char.target, average='macro'), \n",
        "                                recall_score(ref_char[tool], ref_char.target, average='macro'), \n",
        "                                f1_score(ref_char[tool], ref_char.target, average='macro')]"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "wdFT7JK3Sy9k",
        "outputId": "639f019b-b1b5-41b7-b014-8cf02493f6cb"
      },
      "source": [
        "res_sents"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ckiptagger</th>\n",
              "      <th>pkuseg</th>\n",
              "      <th>fastHan</th>\n",
              "      <th>PyNLPIR</th>\n",
              "      <th>stanza</th>\n",
              "      <th>spacy</th>\n",
              "      <th>ltp</th>\n",
              "      <th>jiagu</th>\n",
              "      <th>lac</th>\n",
              "      <th>snownlp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.846684</td>\n",
              "      <td>0.976035</td>\n",
              "      <td>0.863100</td>\n",
              "      <td>0.807024</td>\n",
              "      <td>0.873907</td>\n",
              "      <td>0.833683</td>\n",
              "      <td>0.800758</td>\n",
              "      <td>0.859309</td>\n",
              "      <td>0.753078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.661129</td>\n",
              "      <td>0.693166</td>\n",
              "      <td>0.899176</td>\n",
              "      <td>0.618964</td>\n",
              "      <td>0.592136</td>\n",
              "      <td>0.648360</td>\n",
              "      <td>0.760681</td>\n",
              "      <td>0.703405</td>\n",
              "      <td>0.736919</td>\n",
              "      <td>0.548268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.775590</td>\n",
              "      <td>0.795851</td>\n",
              "      <td>0.919571</td>\n",
              "      <td>0.633303</td>\n",
              "      <td>0.755763</td>\n",
              "      <td>0.761584</td>\n",
              "      <td>0.846003</td>\n",
              "      <td>0.830302</td>\n",
              "      <td>0.872074</td>\n",
              "      <td>0.625240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>0.684558</td>\n",
              "      <td>0.720596</td>\n",
              "      <td>0.907689</td>\n",
              "      <td>0.616320</td>\n",
              "      <td>0.612906</td>\n",
              "      <td>0.674977</td>\n",
              "      <td>0.781148</td>\n",
              "      <td>0.724648</td>\n",
              "      <td>0.769829</td>\n",
              "      <td>0.561630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ckiptagger    pkuseg   fastHan  ...     jiagu       lac   snownlp\n",
              "accuracy     0.717647  0.846684  0.976035  ...  0.800758  0.859309  0.753078\n",
              "precision    0.661129  0.693166  0.899176  ...  0.703405  0.736919  0.548268\n",
              "recall       0.775590  0.795851  0.919571  ...  0.830302  0.872074  0.625240\n",
              "f1_score     0.684558  0.720596  0.907689  ...  0.724648  0.769829  0.561630\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 460
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqws1aBTTBcq"
      },
      "source": [
        "## Parallel alignment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s74zPjzm33DH"
      },
      "source": [
        "# align tags \n",
        "def ruRef(table, model, test, model_name, test_name):\n",
        "    tags = []\n",
        "    for m, t in zip(model, test):\n",
        "        if t in table[table[model] == m][test].iloc[0]:\n",
        "            new = m\n",
        "        else:\n",
        "            new = t\n",
        "        tags.append(new)\n",
        "    return tag_rus"
      ],
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GceAR6SlENQl"
      },
      "source": [
        "# load phar files\n",
        "def open_phar(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        phar = f.readlines()\n",
        "    return [p.split() for p in phar]"
      ],
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4DGY__8TV0f"
      },
      "source": [
        "phar125 = open_phar('/pos/alignment/gold2_125.phar')\n",
        "phar365 = open_phar('pos/alignment/gold4_900.phar')"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObCVltjqyRJq"
      },
      "source": [
        "# to concatenate later\n",
        "char_125 = sum(sentences.loc['gold2_125'].token.apply(lambda x: sum([len(i) for i in x])))\n",
        "char_900 = sum(sentences.loc['gold4_365'].token.apply(lambda x: sum([len(i) for i in x])))+sum(sentences.loc['gold4_continue'].token.apply(lambda x: sum([len(i) for i in x])))\n"
      ],
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE99zSv_FMs8"
      },
      "source": [
        "## Get aligned tags\n",
        "\n",
        "def align(zh, ru, phar, N):\n",
        "    '''\n",
        "    zh -> \n",
        "    '''\n",
        "    length = len(zh)\n",
        "    ruword = ['' for i in range(N)]\n",
        "    rupos = ['' for i in range(N)]\n",
        "    count = 0\n",
        "    for id_sent in range(length):\n",
        "        df = zh[zh.id_sent == id_sent][['id_token', 'pos']]\n",
        "        for lst in df.id_token[0]:\n",
        "            for id_token in lst:\n",
        "                id_token = int(id_token)\n",
        "                for pair in phar[id_sent]:\n",
        "                    pair = [int(i) for i in pair.split('-')]\n",
        "                    if id_token == pair[1]:\n",
        "                        try:\n",
        "                            ruword[count] = ru[(ru.id_sent == id_sent) & (ru.id_token == pair[0])].word.iloc[0]\n",
        "                            rupos[count] = ru[(ru.id_sent == id_sent) & (ru.id_token == pair[0])].pos.iloc[0]\n",
        "                        except:\n",
        "                            print(count)\n",
        "\n",
        "                count += 1\n",
        "    return ruword, rupos"
      ],
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJBfIPaslVtV"
      },
      "source": [
        "a, b = align(sentences[:126], ru[ru.nickname == 'gold2'], phar125, char_125)\n",
        "c, d = align(sentences[126:], ru[(ru.nickname == 'gold4')|(ru.nickname == 'gold4_continue')], phar365, char_900)"
      ],
      "execution_count": 500,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHT58jyjVA6o"
      },
      "source": [
        "ref_char['pymorphy'] = b+d\n",
        "ref_char['rus'] = a+c\n",
        "ref_char['pymorphy'] = ref_char.pymorphy.apply(lambda x: str(x))"
      ],
      "execution_count": 519,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmfWZbdPekUH"
      },
      "source": [
        "# ref_char.to_csv('/content/drive/MyDrive/data/parallel_rus_22.csv') ##ckeckpoint\n",
        "# ref_char = pd.read_csv('/content/drive/MyDrive/data/parallel_rus_22.csv') #load back"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "_LFlt0ZRKfi2",
        "outputId": "08405079-a961-49cd-f3c0-10fd549f7b1b"
      },
      "source": [
        "# Accuracy by proper nouns\n",
        "\n",
        "N_nr = ref_char[ref_char.target=='NR'].shape[0]\n",
        "NRs = pd.DataFrame(columns = pos_tools)\n",
        "for tool in pos_tools:\n",
        "    a = ref_char[(ref_char.target=='NR')&(ref_char[tool] == 'NR')].shape[0]/N_nr\n",
        "    NRs[tool] = [a]\n",
        "NRs"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ckiptagger</th>\n",
              "      <th>pkuseg</th>\n",
              "      <th>fastHan</th>\n",
              "      <th>PyNLPIR</th>\n",
              "      <th>stanza</th>\n",
              "      <th>spacy</th>\n",
              "      <th>ltp</th>\n",
              "      <th>jiagu</th>\n",
              "      <th>lac</th>\n",
              "      <th>snownlp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.672262</td>\n",
              "      <td>0.824591</td>\n",
              "      <td>0.986991</td>\n",
              "      <td>0.835501</td>\n",
              "      <td>0.866135</td>\n",
              "      <td>0.728493</td>\n",
              "      <td>0.874528</td>\n",
              "      <td>0.405791</td>\n",
              "      <td>0.928242</td>\n",
              "      <td>0.602602</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ckiptagger    pkuseg   fastHan  ...     jiagu       lac   snownlp\n",
              "0    0.672262  0.824591  0.986991  ...  0.405791  0.928242  0.602602\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av1P9BS3fQw-"
      },
      "source": [
        "### Describe parallel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8II7m7u3c3Ym",
        "outputId": "8573f550-6844-49e8-90d1-a987fb0cc32c"
      },
      "source": [
        "print(f'Число сопоставленных символов: {ref_char[ref_char.pymorphy != \"\"].shape[0]}')\n",
        "print(f'Процент сопоставленных символов: {ref_char[ref_char.pymorphy != \"\"].shape[0]/N_char}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Число сопоставленных символов: 31921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ5vOQPUgbT2",
        "outputId": "ff49cd70-85c0-46db-aec9-6f3c4476c52f"
      },
      "source": [
        "print('Среди сопоставленных слов преобладают части речи: ')\n",
        "ref_char[ref_char.pymorphy != \"\"].target.value_counts()"
      ],
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Среди сопоставленных слов преобладают части речи: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN     2511\n",
              "VV     2219\n",
              "PU     1460\n",
              "AD     1163\n",
              "NR      827\n",
              "PN      606\n",
              "VA      402\n",
              "P       242\n",
              "JJ      231\n",
              "AS      205\n",
              "CD      183\n",
              "DT      144\n",
              "M       140\n",
              "DEC     138\n",
              "DEG     138\n",
              "LC      130\n",
              "NT      115\n",
              "SP       94\n",
              "CC       76\n",
              "VC       61\n",
              "VE       57\n",
              "DEV      56\n",
              "CS       34\n",
              "OD       21\n",
              "IJ       20\n",
              "DER      18\n",
              "SB       12\n",
              "MSP       6\n",
              "BA        6\n",
              "LB        5\n",
              "ON        4\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otDAOvnVg3Ze"
      },
      "source": [
        "### Transfer russian tags to chinese\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNVguoFVgqyc"
      },
      "source": [
        "ref_char = ref_char.fillna('')"
      ],
      "execution_count": 551,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1pJcOvY1V2i",
        "outputId": "3eb41f41-b5c6-4145-8aae-39c632457f85"
      },
      "source": [
        "## Get correct tags\n",
        "compare_char(ref_table, ref_char['pymorphy'], ref_char['target'], 'pymorphy')\n",
        "res_sents['pymorphy'] = [accuracy_score(ref_char['pymorphy'], ref_char.target),\n",
        "                                precision_score(ref_char['pymorphy'], ref_char.target, average='macro'), \n",
        "                                recall_score(ref_char['pymorphy'], ref_char.target, average='macro'), \n",
        "                                f1_score(ref_char['pymorphy'], ref_char.target, average='macro')]"
      ],
      "execution_count": 562,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31921it [00:06, 5140.21it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9piBvio6hkYM"
      },
      "source": [
        "# ref_char.to_csv('/content/drive/MyDrive/data/parallel_DONE.csv') #вариант после перевода"
      ],
      "execution_count": 542,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmORoik4i2Ep",
        "outputId": "74e3131a-4c6a-45be-dddf-9fdd297e11dc"
      },
      "source": [
        "print(f'Теги соответствуют верным в {ref_char[ref_char.target == ref_char.pymorphy].shape[0]} случаях из {N_char}')"
      ],
      "execution_count": 546,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Теги соответствуют верным в 7300 случаях из 31921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV-Ayqi0MjXE"
      },
      "source": [
        "df_char['pymorphy'] = a.pymorphy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoLJq2OOe26T"
      },
      "source": [
        "mostFreqDict['pymorphy'] = mostFreq('pymorphy')"
      ],
      "execution_count": 555,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD7TFMy7SrOe",
        "outputId": "d43ed8d3-6e63-423d-8038-907e287eda6e"
      },
      "source": [
        "### Replace with most fequent\n",
        "for tool in ['pymorphy']:\n",
        "    print(tool)\n",
        "    for k, pair in enumerate(zip(ref_char[tool], ref_char.target)):\n",
        "        tag, tar = pair[0], pair[1]\n",
        "        if tag != tar:\n",
        "            if tag not in mostFreqDict[tool]:\n",
        "                continue\n",
        "            else:\n",
        "                ref_char[tool][k] = mostFreqDict[tool][tag]"
      ],
      "execution_count": 556,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pymorphy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JudHogHpBA0"
      },
      "source": [
        "def metrics(yt, yp):\n",
        "    return [accuracy_score(yt, yp),\n",
        "                                precision_score(yt, yp, average='macro'), \n",
        "                                recall_score(yt, yp, average='macro'), \n",
        "                                f1_score(yt, yp, average='macro')]"
      ],
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZYdz4UJdfhX",
        "outputId": "d85ba8e4-d4cc-48b0-d43c-60c12f0c69a5"
      },
      "source": [
        "# Add metrics\n",
        "\n",
        "res_sents['pymorphy_new'] = [accuracy_score(ref_char['pymorphy'], ref_char.target),\n",
        "                                precision_score(ref_char['pymorphy'], ref_char.target, average='macro'), \n",
        "                                recall_score(ref_char['pymorphy'], ref_char.target, average='macro'), \n",
        "                                f1_score(ref_char['pymorphy'], ref_char.target, average='macro')]"
      ],
      "execution_count": 557,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQeDThXF2YqS"
      },
      "source": [
        "# ref_char.to_csv('/content/drive/MyDrive/data/parallel.csv')\n",
        "# ref_char = pd.read_csv('/content/drive/MyDrive/data/parallel.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThnbnUmbmJSS"
      },
      "source": [
        "### Apply Russian tags only on aligned parts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSzXUhKxm3QX"
      },
      "source": [
        "ref_char['experiment'] = [tag if tag != '' else '' for i, tag in enumerate(ref_char.pymorphy)]"
      ],
      "execution_count": 567,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LIIshDLMJYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286451d0-1b42-454f-a4bb-50f213ebb41c"
      },
      "source": [
        "res_sents['pymorphy_only_exist'] = metrics(ref_char[ref_char.experiment != ''].target, \n",
        "                                           ref_char[ref_char.experiment != ''].pymorphy)\n",
        "# accuracy_score(ref_char[ref_char.experiment != ''].target, ref_char[ref_char.experiment != ''].pymorphy)\n",
        "## очень неплохо :)"
      ],
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj1OifDwoK0i"
      },
      "source": [
        "## fastHan + Pymorphy2 if fastHan is wrong\n",
        "\n",
        "ref_char['combo'] = [tag if tag == ref_char.target[i] else ref_char.pymorphy[i] for i, tag in enumerate(ref_char.fastHan)]"
      ],
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljMG8MT8qG2I",
        "outputId": "b7c5d9f8-3505-4085-b927-fe1f3be1316d"
      },
      "source": [
        "res_sents['combo'] = metrics(ref_char.target, ref_char.combo)"
      ],
      "execution_count": 578,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "4J8ZYMBqGidS",
        "outputId": "b3931957-3632-4c0d-fc57-2bdbbf9ff7e9"
      },
      "source": [
        "## Full results\n",
        "res_sents "
      ],
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ckiptagger</th>\n",
              "      <th>pkuseg</th>\n",
              "      <th>fastHan</th>\n",
              "      <th>PyNLPIR</th>\n",
              "      <th>stanza</th>\n",
              "      <th>spacy</th>\n",
              "      <th>ltp</th>\n",
              "      <th>jiagu</th>\n",
              "      <th>lac</th>\n",
              "      <th>snownlp</th>\n",
              "      <th>pymorphy</th>\n",
              "      <th>pymorphy_only_exist</th>\n",
              "      <th>combo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.663670</td>\n",
              "      <td>0.827700</td>\n",
              "      <td>0.976035</td>\n",
              "      <td>0.830801</td>\n",
              "      <td>0.807024</td>\n",
              "      <td>0.871558</td>\n",
              "      <td>0.819053</td>\n",
              "      <td>0.780865</td>\n",
              "      <td>0.847373</td>\n",
              "      <td>0.703267</td>\n",
              "      <td>0.253657</td>\n",
              "      <td>0.715030</td>\n",
              "      <td>0.976692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.276166</td>\n",
              "      <td>0.388939</td>\n",
              "      <td>0.899176</td>\n",
              "      <td>0.223502</td>\n",
              "      <td>0.419430</td>\n",
              "      <td>0.443491</td>\n",
              "      <td>0.451724</td>\n",
              "      <td>0.369516</td>\n",
              "      <td>0.430320</td>\n",
              "      <td>0.273940</td>\n",
              "      <td>0.124686</td>\n",
              "      <td>0.711860</td>\n",
              "      <td>0.914032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recall</td>\n",
              "      <td>0.379683</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.919571</td>\n",
              "      <td>0.271930</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.630504</td>\n",
              "      <td>0.405064</td>\n",
              "      <td>0.875544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f1_score</td>\n",
              "      <td>0.290562</td>\n",
              "      <td>0.424474</td>\n",
              "      <td>0.907689</td>\n",
              "      <td>0.243067</td>\n",
              "      <td>0.468110</td>\n",
              "      <td>0.484565</td>\n",
              "      <td>0.496496</td>\n",
              "      <td>0.410596</td>\n",
              "      <td>0.468906</td>\n",
              "      <td>0.309400</td>\n",
              "      <td>0.190675</td>\n",
              "      <td>0.455018</td>\n",
              "      <td>0.892843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ckiptagger    pkuseg  ...  pymorphy  pymorphy_only_exist     combo\n",
              "0   accuracy    0.663670  0.827700  ...  0.253657             0.715030  0.976692\n",
              "1  precision    0.276166  0.388939  ...  0.124686             0.711860  0.914032\n",
              "2     recall    0.379683  0.500000  ...  0.630504             0.405064  0.875544\n",
              "3   f1_score    0.290562  0.424474  ...  0.190675             0.455018  0.892843\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 579
        }
      ]
    }
  ]
}